<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">

    <meta property="og:title" content="Monkey See, Monkey Do: Harnessing Self-attention in Motion Diffusion for Zero-shot Motion Transfer"/>
    <meta property="og:url" content="https://MonkeySeeDoCG.github.io/MoMo-page/"/>
    <meta property="og:image:width" content="1200"/>
    <meta property="og:image:height" content="630"/>


    <title>Monkey See, Monkey Do: Harnessing Self-attention in Motion Diffusion for Zero-shot Motion Transfer</title>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-PQ3PYPGJRH"></script>
    <script>
        window.dataLayer = window.dataLayer || [];

        function gtag() {
            dataLayer.push(arguments);
        }

        gtag('js', new Date());

        gtag('config', 'G-PQ3PYPGJRH');
    </script>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
          rel="stylesheet">
    <link rel="icon" href="media/figures/cute-monkey-cartoon-face-simple-vector-48682892.png ">

    <link rel="stylesheet" href="static/css/bulma.min.css">
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet"
          href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="static/css/index.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
    <script defer src="static/js/fontawesome.all.min.js"></script>
    <script src="static/js/bulma-carousel.min.js"></script>
    <script src="static/js/bulma-slider.min.js"></script>
    <script src="static/js/index.js"></script>

    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>


<body>

<section class="publication-header">
    <div class="hero-body">
        <div class="container is-max-widescreen">
            <!-- <div class="columns is-centered"> -->
            <div class="column has-text-centered">
                <h1 class="title is-1 publication-title">Monkey See, Monkey Do: Harnessing Self-attention in Motion Diffusion for Zero-shot Motion Transfer</h1>
                <h1 class="title is-1 publication-title">(MoMo)</h1>
            </div>
        </div>
    </div>

</section>

<section class="publication-author-block">

    <div class="hero-body">
        <div class="container is-max-desktop">
            <div class="columns is-centered">
                <div class="column has-text-centered">
<!--
                    to anonimyze:
                    1. remove author names (till "..indicates equal...")
                    2. change link to video.
                    3. remove bibtex reference.
-->
        <!--div class="column has-text-centered">
              <div class="is-size-4 publication-authors">
                <span class="author-block">Conference Name 2024</span>
              </div>
        </div-->
                    
<!--
        <div class="column has-text-centered">
            <div class="is-size-4 publication-authors">
                <span class="author-block">
                    <a href="https://sigal-raab.github.io/" target="_blank">Sigal Raab</a>*,
                    <a href="https://guytevet.github.io/" target="_blank">Guy Tevet</a>,
                    <br/>
                    <a href="https://www.cs.tau.ac.il/~amberman/" target="_blank">Amit H. Bermano</a>,
                    <a href="https://danielcohenor.com/" target="_blank">Daniel Cohen-Or</a></span>
                    <sup></sup></span>
            </div>
        </div>

        <div class="is-size-5 publication-authors">
            <span class="author-block">Tel Aviv University, Israel, Reichman University, Israel</span>
        </div>
    -->

                    <div class="column has-text-centered">
                        <div class="publication-links">
                            <span class="link-block">
                                <!--a href="https://arxiv.org/abs/2302.05905" target="_blank"
                                class="external-link button is-normal is-rounded"-->
                                <a href="anonymous_paper.pdf" target="_blank" class="external-link button is-normal is-rounded"> 
                                <span class="icon">
                                    <i class="ai ai-arxiv"></i>
                                </span>
                                <span>Paper</span>
                                </a>
                            </span>

                            <span class="link-block">
                                <a href="https://github.com/MonkeySeeDoCG/MoMo-code" target="_blank"
                                class="external-link button is-normal is-rounded">
                                <span class="icon">
                                <i class="fab fa-github"></i>
                                </span>
                                <span>Code</span>
                                </a>
                            </span>

                            <span class="link-block">
                            <a href="https://www.youtube.com/watch?v=abcdefg" target="_blank"
                                class="external-link button is-normal is-rounded">
                                <span class="icon">
                                <i class="fab fa-youtube"></i>
                                </span>
                                <span>Video</span>
                                </a>
                            </span>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>

<!-- <section class="hero teaser">
    <div class="container is-max-desktop">
        <div class="hero-body">

            <div class="column is-centered has-text-centered">
                  <img src="media/figures/teaser_fp_short.jpg" alt="Motion Transfer" width="80%">
            </div>
            <h2 class="subtitle has-text-justified">
                <b>Motion transfer.</b> The top row displays a leader performing a walking motion. The left column showcases sample frames of four followers, each engaged in a different motion. 
                The central block presents the output motion, where the outline of the leader's motion (e.g., leading leg) is transferred to the followers and integrated with their distinct motifs. 
                Note the alignment of the steps for the leader and the output motions.  
                Our motion transfer is conducted by manipulating self-attention latent features in a zero-shot fashion.
            </h2>

        </div>
    </div>
</section> -->


<!-- Video + Abstract -->
<section class="section hero is-light">
    <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <div class="item">
                    <p style="margin-bottom: 30px">
                        <!-- anonymous SIGA-->
                        <iframe width="760" height="428" src="https://www.youtube.com/embed/AmLaW0qI43Q"  
                                title="YouTube video player" frameborder="0"
                                allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                                allowfullscreen></iframe>

                    </p>
                </div>
                <h2 class="title is-3">Abstract</h2>
                <div class="content has-text-justified">
                    <p>
                        Given the remarkable results of motion synthesis with diffusion models, a
                        natural question arises: how can we effectively leverage these models for mo-
                        tion editing? Existing diffusion-based motion editing methods overlook the
                        profound potential of the prior embedded within the weights of pre-trained
                        models, which enables manipulating the latent feature space; hence, they
                        primarily center on handling the motion space. In this work, we explore the
                        attention mechanism of pre-trained motion diffusion models. We uncover the
                        roles and interactions of attention elements in capturing and representing
                        intricate human motion patterns, and carefully integrate these elements to
                        transfer a leader motion to a follower one while maintaining the nuanced
                        characteristics of the follower, resulting in zero-shot motion transfer. Editing
                        features associated with selected motions allows us to confront a challenge
                        observed in prior motion diffusion approaches, which use general directives
                        (e.g., text, music) for editing, ultimately failing to convey subtle nuances
                        effectively. Our work is inspired by how a monkey closely imitates what it
                        sees while maintaining its unique motion patterns; hence we call it Monkey
                        see, Monkey Do, and dub it MoMo. Employing our technique enables accom-
                        plishing tasks such as synthesizing out-of-distribution motions, style transfer,
                        and spatial editing. Furthermore, diffusion inversion is seldom employed
                        for motions; as a result, editing efforts focus on generated motions, limiting
                        the editability of real ones. MoMo harnesses motion inversion, extending its
                        application to both real and generated motions. Experimental results show
                        the advantage of our approach over the current art. In particular, unlike
                        methods tailored for specific applications through training, our approach is
                        applied at inference time, requiring no training. 
                    </p>
                </div>
             </div>
        </div>
    </div>
</section>

<!-- Motion Transfer -->
<section class="hero is-small ">
    <div class="hero-body">
        <div class="container is-max-desktop">
            <div class="content has-text-centered">
                <h2 class="title is-3">Motion Transfer</h2>
            </div>
            <div class="content">
                <p>
                Leveraging our understanding of motion self-attention (detailed below), we have developed an innovative motion transfer framework, 
                where the outline of a leader motion is transfered to a follower one, while preserving the motion motifs of the follower.
                </p>
                <p>
                The term <b>outline</b> relates to <b>what</b> the character is doing, and <b>when</b>.
                It provides a visual blueprint for the sequence of actions and transitions needed to execute the motion.
                </p>
                <p>
                The term <b>motifs</b> relates to <b>how</b> a motion is performed.
                It includes subtle nuances, gestures, or patterns that convey meaning and emotion. 
                </p>
                <!-- <p>
                The outline and motifs are implicitly derived from the leader and follower motions, respectively. 
                 </p> -->
            </div>
        </div>
    </div>
</section>
        

<section class="section hero">
    <div class="container is-max-desktop">               
        <div class="columns is-centered is-four-fifths">
            <div class="column is-centered has-text-centered">
                <video poster="" id="tree" playsinline autoplay muted loop width="100%">
                    <source src="media/videos/ballet_circle/ballet_circle_leader_only.mp4"
                            type="video/mp4">
                </video>
                <p><b>Leader</b></p>
            </div>
            <div class="column is-centered has-text-centered">
                <video poster="" id="tree" playsinline autoplay muted loop width="100%">
                    <source src="media/videos/ballet_circle/ballet_circle_follower.mp4"
                                type="video/mp4">
                </video>
                <p><b>Follower</b></p>
            </div>
            <!-- <div class="column is-centered has-text-centered"> -->
            <div class="column is-centered has-text-centered">
                    <video poster="" id="tree" playsinline autoplay muted loop width="100%">
                    <source src="media/videos/ballet_circle/ballet_circle_leader_out.mp4"
                                type="video/mp4">
                </video>
                <p><b>Output</b> (vs. Leader)</p>
            </div>
        </div>
        <p>In the example above, the output motion precisely follows the steps and rhythm outline of the leader, while also incorporating the dancing motifs of the follower.</p>
    </div>
</section>

<!-- Pipeline -->
<section class="hero is-small is-light">
    <div class="hero-body">
        <div class="container is-max-desktop">
            <div class="content has-text-centered">
                <h2 class="title is-3">Pipeline</h2>
                <img src="media/figures/final_arch_pdf.png" width="40%">
            </div>
            <div class="content">
                <p>
                    The input to our model is two noisy tensors, \( X_T^\text{flw} \) and \( X_T^\text{ldr} \), produced by either inverting real motions or sampling a Gaussian noise.
                    The two tensors represent leader and follower motions, and are given along with their associated text prompts.
                    We initialize our output motion, \( X_T^\text{out} \), using the initial noise from the leader motion and pair it with the text prompt from the follower motion.
                    The three noised motions \( X_t^\text{ldr} \), \( X_t^\text{flw} \) and \( X_t^\text{out} \), are passed to the frozen denoising network at each timestep \( t \), along with their prompts and with \( t \).
                    Within the denoising network, \( X_t^\text{out} \) undergoes <b>mixed-attention</b> by combining the query from the leader motion with the key and value from the follower motion. 
                    Meanwhile, \( X_t^\text{ldr} \) and \( X_t^\text{flw} \) follow a standard diffusion process.                
                </p>
            </div>
        </div>
    </div>
</section>


<!-- Understanding Self-Attention -->
<section class="hero is-small ">
    <div class="hero-body">
        <div class="container is-max-desktop">
            <div class="content has-text-centered">
                <h2 class="title is-3">Understanding Self-Attention Features</h2>
            </div>
            <div class="content">
                <p>
                    Analyzing the profound potential embedded in the self-attention features, we show that <b>keys</b> mainly encode motion <b>motifs</b>, while <b>queries</b> mainly encapsulate its <b>outline</b>.
                    This key insight leads the design of MoMo.
                </p>
            </div>
        </div>
    </div>
</section>
<section class="hero is-small ">
    <div class="hero-body">
        <div class="container is-max-desktop">
             <div class="columns is-centered is-four-fifths">
                <div class="column is-centered ">
                    <video poster="" id="tree" playsinline autoplay muted loop width="100%">
                        <source src="media/videos/QK/Key.mov"
                                type="video/mp4">
                    </video>
                    <p>When clustering key features, their unique motifs, such as ‘standing’, ‘walking’ or ‘turning’ are grouped into different clusters.
                    </p>
                </div>
                <div class="column is-centered">
                    <video poster="" id="tree" playsinline autoplay muted loop width="100%">
                        <source src="media/videos/QK/Query.mov"
                                    type="video/mp4">
                    </video>
                    <p>When clustering query features, periodic steps are grouped together, indicating a dominance of outline features, such as locomotion phases, 
                        <!-- and of temporal information,  -->
                        over their unique motifs.
                    </p>
                </div>
            </div>
            <br>
            <br>

            <div class="column is-centered has-text-centered">
                <img src="media/figures/nn.jpg" width="60%">
            </div>
            <div class="content">
                <p><b>Correspondence via attention.</b>
                    Follower frames are color-coded according to consecutive indices (top row). 
                    Nearest neighbor follower frames (bottom) are the ones that achieve the highest mixed-attention ( \( Q^{\text\text{ldr}} \cdot K^{\text\text{flw}^T} \) ) activation, 
                    shown respectively to leader's frames (middle row).
                    As shown, these correspondences are semantically aligned, e.g., moving ``up'' and ``down'' sub-motions are consistently assigned with follower moving ``up'' and ``down'' frames. 
                    Some of the nearest neighbors are highlighted with arrows.
                </p>
            </div>
        </div>
    </div>
</section>

<!-- Motion Transfer Special Cases -->
<section class="hero is-small is-light">
    <div class="hero-body">
        <div class="container is-max-desktop">
            <div class="content has-text-centered">
                <h2 class="title is-3">Special Cases of Motion Transfer</h2>
            </div>
            <div class="content">
                <p>
                    Our framework offers a versatile motion transfer technique, facilitating various tasks of transferring motifs from one motion to another.
                    Below are several tasks that constitute special cases of our framework.
                </p>
            </div>
        </div>
    </div>
</section>
<!-- Spatial Editing -->
<section class="hero is-small">
    <div class="hero-body">
        <div class="container is-max-desktop">
            <div class="columns is-centered is-four-fifths">
                <div class="column is-centered has-text-centered">
                    <video poster="" id="tree" playsinline autoplay muted loop width="100%">
                        <source src="media/videos/raise_hands/raise_leader.mp4"
                                type="video/mp4">
                    </video>
                    <p><b>Leader</b></p>
                </div>
                <div class="column is-centered has-text-centered">
                    <video poster="" id="tree" playsinline autoplay muted loop width="100%">
                        <source src="media/videos/raise_hands/raise_follower.mp4"
                                    type="video/mp4">
                    </video>
                    <p><b>Follower</b></p>
                </div>
                <!-- <div class="column is-centered has-text-centered"> -->
                <div class="column is-centered has-text-centered">
                        <video poster="" id="tree" playsinline autoplay muted loop width="100%">
                        <source src="media/videos/raise_hands/raise_out_leader.mp4"
                                    type="video/mp4">
                    </video>
                    <p><b>Output</b> (vs. Leader)</p>
                </div>
            </div>
            <p><b>Spatial Editing</b>, is where specific joints, like the arms, are edited, while the overall motion is preserved.
            </p>
        </div>
    </div>
</section>
<!-- Action Transfer-->
<section class="hero is-small">
    <div class="hero-body">
        <div class="container is-max-desktop">
            <div class="columns is-centered is-four-fifths">
                <div class="column is-centered has-text-centered">
                    <video poster="" id="tree" playsinline autoplay muted loop width="100%">
                        <source src="media/videos/crawl/leader.mp4"
                                type="video/mp4">
                    </video>
                    <p><b>Leader</b></p>
                </div>
                <div class="column is-centered has-text-centered">
                    <video poster="" id="tree" playsinline autoplay muted loop width="100%">
                        <source src="media/videos/crawl/crawl_follower.mp4"
                                    type="video/mp4">
                    </video>
                    <p><b>Follower</b></p>
                </div>
                <div class="column is-centered has-text-centered">
                        <video poster="" id="tree" playsinline autoplay muted loop width="100%">
                        <source src="media/videos/crawl/crawl.mp4"
                                    type="video/mp4">
                    </video>
                    <p><b>Output</b> (vs. Leader)</p>
                </div>
            </div>
            <p><b>Action Transfer</b>, is where Here the leader and the follower motions are completely different, 
                and yet the output still imitates the follower's actions, but in the same rhythm and limb order as the leader.
            </p>
        </div>
    </div>
</section>

<!-- Style Transfer-->
<section class="hero is-small">
    <div class="hero-body">
        <div class="container is-max-desktop">
            <div class="columns is-centered is-four-fifths">
                <div class="column is-centered has-text-centered">
                    <video poster="" id="tree" playsinline autoplay muted loop width="100%">
                        <source src="media/videos/monkey_walk/leader.mp4"
                                type="video/mp4">
                    </video>
                    <p><b>Leader</b></p>
                </div>
                <div class="column is-centered has-text-centered">
                    <video poster="" id="tree" playsinline autoplay muted loop width="100%">
                        <source src="media/videos/monkey_walk/monkey_follower.mp4"
                                    type="video/mp4">
                    </video>
                    <p><b>Follower</b></p>
                </div>
                <div class="column is-centered has-text-centered">
                        <video poster="" id="tree" playsinline autoplay muted loop width="100%">
                        <source src="media/videos/monkey_walk/monkey_fix.mp4"
                                    type="video/mp4">
                    </video>
                    <p><b>Output</b> (vs. Leader)</p>
                </div>
            </div>
            <p><b>Style Transfer</b> refers to doing a given motion in a different way that represents an emotion or a physical state, such as ``happily'' or ``like a monkey’’.
            </p>
        </div>
    </div>
</section>

<!-- OOD-->
<section class="hero is-small">
    <div class="hero-body">
        <div class="container is-max-desktop">
            <div class="columns is-centered is-four-fifths">
                <div class="column is-centered has-text-centered">
                    <video poster="" id="tree" playsinline autoplay muted loop width="100%">
                        <source src="media/videos/monkey_dance/gorilla_dance_leader.mp4"
                                type="video/mp4">
                    </video>
                    <p><b>Leader</b></p>
                </div>
                <div class="column is-centered has-text-centered">
                    <video poster="" id="tree" playsinline autoplay muted loop width="100%">
                        <source src="media/videos/monkey_dance/gorilla_dance_follower.mp4"
                                    type="video/mp4">
                    </video>
                    <p><b>Follower</b></p>
                </div>
                <div class="column is-centered has-text-centered">
                        <video poster="" id="tree" playsinline autoplay muted loop width="100%">
                        <source src="media/videos/monkey_dance/gorilla_dance.mp4"
                                    type="video/mp4">
                    </video>
                    <p><b>Output</b> (vs. Leader)</p>
                </div>
            </div>
            <p><b>Out Of Distribution Synthesis</b> entails uncommon motions that pose a challenge to the network's generalization capabilities. 
                In this example, the follower is the network’s attempt to generate a dancing gorilla. However, this attempt fails to dance.
                By applying MoMo on the other hand, we generate a person that dances in the same outline as the leader, but with the motifs of the gorilla.
            </p>
        </div>
    </div>
</section>


<!-- Inversion -->
<section class="hero is-small is-light">
    <div class="hero-body">
        <div class="container is-max-desktop">
            <div class="content has-text-centered">
                <h2 class="title is-3">Inversion</h2>
            </div>
            <div class="content">
                <p>
                    Our work stands as the sole approach capable of utilizing motion DDIM inversion within diffusion models, extending its application to both real and generated motions.
                </p>
            </div>
        </div>
    </div>
</section>
<section class="hero is-small">
    <div class="hero-body">
        <div class="container is-max-desktop">
            <div class="columns is-centered is-four-fifths">
                <div class="column is-centered has-text-centered">
                    <video poster="" id="tree" playsinline autoplay muted loop width="100%">
                        <source src="media/videos/inversion/invert_leader.mp4"
                                type="video/mp4">
                    </video>
                    <p><b>Leader</b> (from dataset)</p>
                </div>
                <div class="column is-centered has-text-centered">
                    <video poster="" id="tree" playsinline autoplay muted loop width="100%">
                        <source src="media/videos/inversion/invert_follower.mp4"
                                    type="video/mp4">
                    </video>
                    <p><b>Follower</b> (from dataset)</p>
                </div>
                <!-- <div class="column is-centered has-text-centered"> -->
                <div class="column is-centered has-text-centered">
                        <video poster="" id="tree" playsinline autoplay muted loop width="100%">
                        <source src="media/videos/inversion/invert_leader_out.mp4"
                                    type="video/mp4">
                    </video>
                    <p><b>Output</b> (vs. Leader)</p>
                </div>
            </div>
            <p>How easy it is to utilize the provided follower motion, while how challenging it would be to generate a motion similar to theirs, using a text prompt.
            </p>
        </div>
    </div>
</section>

<!-- BibTeX -->

<!-- <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
        <h2 class="title">BibTeX</h2>
        <pre><code>
            @inproceedings{raab2024single,
            title={Single Motion Diffusion},
            author={Raab, Sigal and Leibovitch, Inbal and Tevet, Guy and Arar, Moab and Bermano, Amit H and Cohen-Or, Daniel},
            booktitle={The Twelfth International Conference on Learning Representations (ICLR)},
            year={2024}
            }
        </code></pre>
    </div>
</section> -->


<footer class="footer">
    <!--  <div class="container">
       <div class="content has-text-centered">
         <a class="icon-link"
         href="https://homes.cs.washington.edu/~kpar/nerfies/videos/nerfies_paper.pdf">
         <i class="fas fa-file-pdf"></i>
       </a>
       <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
         <i class="fab fa-github"></i>
       </a>
     </div> -->
    <div class="columns is-centered">
        <div class="column is-8">
            <div class="content">
                <p>
                    This website is licensed under a <a rel="license"
                                                        href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                    Commons Attribution-ShareAlike 4.0 International License</a>.
                </p>
                <p>
                    Website source code based on the <a href="https://nerfies.github.io/"> Nerfies</a> project page. If
                    you want to reuse their <a
                        href="https://github.com/nerfies/nerfies.github.io">source code</a>, please credit them
                    appropriately.
                </p>
            </div>
        </div>
    </div>
    </div>
</footer>


<script type="text/javascript">
    var sc_project = 12351448;
    var sc_invisible = 1;
    var sc_security = "c676de4f";
</script>
<script type="text/javascript"
        src="https://www.statcounter.com/counter/counter.js"
        async></script>
<noscript>
    <div class="statcounter"><a title="Web Analytics"
                                href="https://statcounter.com/" target="_blank"><img
            class="statcounter"
            src="https://c.statcounter.com/12351448/0/c676de4f/1/"
            alt="Web Analytics"></a></div>
</noscript>
<!-- End of Statcounter Code -->

</body>
</html>
